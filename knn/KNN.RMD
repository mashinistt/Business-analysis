---
title: "KNN"
author: "Владимир Шаталов"
date: "14 октября 2016 г."
output: html_document
---

В данной задаче предсказываем область, в которой производилось оливковое масло.

```{r}
knitr::opts_chunk$set(fih.height=20,fig.width=10,fig.align="center")

```
Загружаем данные
```{r}
olive<-read.table("D:\\olive_data.csv", header=F,sep=";")
names(olive)<-c("area","region","palmitic","palmitoleic","stearic", "oleic","linoleic","linolenic","arachidic",
               "eicosenoic")
knitr::kable(olive[1:10,])
```
Разобъем данные на обучающую и тестовую выборки. 
```{r}
set.seed(1001)
olive2<-olive[,-c(2)]
s<-sample(1:nrow(olive2),400,replace=F)
train<-as.data.frame(scale(olive2[s,-1]))
train_labels<-as.factor(olive2[s,1])
test<-as.data.frame(scale(olive2[-s,-1]))
test_labels<-as.factor(olive2[-s,1])
```
Посмотрим на получившиеся выборки.
```{r}
barplot(table(olive2[,1]),main="Распределение классов на всем множестве",col="#247ba0")
barplot(table(olive2[s,1]),main="Распеределение классов на обучающем множестве",col="#247ba0")
barplot(table(olive2[-s,1]),main="Распеределение классов на тестовом множестве",col="#247ba0")
```
Как видим распределения классов примерно одинаковы во всех выборках.

```{r,warning=FALSE,message=FALSE}
library(class)
library(ggplot2)
```
Попробуем подобрать параметр k несколько раз
```{r}
set.seed(42)
a<-rep(0,15)
for( i in 1:15){
  classifier<-knn(train,test,train_labels,k=i)
  a[i]<-sum(classifier!=test_labels)
}
a
set.seed(46)
a<-rep(0,15)
for( i in 1:15){
  classifier<-knn(train,test,train_labels,k=i)
  a[i]<-sum(classifier!=test_labels)
}
a
set.seed(47)
a<-rep(0,15)
for( i in 1:15){
  classifier<-knn(train,test,train_labels,k=i)
  a[i]<-sum(classifier!=test_labels)
}
a
```
Как видим количество ошибок отличается незначительно, однако однозначно выбрать k довольно затруднительно. Поэтому используем кросс-валидацию с фолдами.
<br>
Сначала перемешаем выборку
```{r}
scv<-sample(1:nrow(olive2),nrow(olive2),replace=F)
olive3<-olive2[scv,]
```
И теперь проведем кросс-валидацию.
```{r}
cv_break<-round(seq(1,572,length.out = 11))
set.seed(1234)
b<-rep(1:15)
for(j in 1:15){
a<-rep(0,10)
for (i in 1:10){
  classifier<-knn(as.data.frame(scale(olive3[-c(cv_break[i]:cv_break[i+1]),-1])),                          as.data.frame(scale(olive3[cv_break[i]:cv_break[i+1],-1])),                              as.factor(olive3[-c(cv_break[i]:cv_break[i+1]),1]),
                  k=j)
   a[i]<-sum(classifier!=as.factor(olive3[c(cv_break[i]:cv_break[i+1]),1]))
}
b[j]<-mean(a)
}
b
which.min(b)
```
Таким образом, выбираем k=3.
```{r}
classifier<-knn(train,test,train_labels,k=3)
sum(classifier!=test_labels)
```
Итого, мы ошиблись в 6 случаях. Посмотрим, где именно.
```{r}
table(classifier,test_labels)
```
Классифицируем масло с характеристиками 1011,  52,  260,	7924,	678,	151,	70,	44. Сперва нормируем параметры.
```{r}
set.seed(1234)
olive_pred<-scale(rbind(olive2[,-1],c(1011,  52,  260,	7924,	678,	151,	70,	44)))
knn(olive_pred[1:572,],olive_pred[573,],as.factor(olive2[,1]),k=3,prob=T)
```
Итого, масло с заданными характеристиками скорее всего произведено в области North-Apulia
Попытаемся визуализировать полученный результат.
```{r}
ol.dist=dist(olive_pred[,c(1:8)])
ol.mds=cmdscale(ol.dist)
ol.mds2<-as.data.frame(cbind(ol.mds[1:572,],olive$area))
ol.mds3<-as.data.frame(ol.mds)
qplot(ol.mds2$V1,ol.mds2$V2,colour=as.factor(ol.mds2$V3))+geom_point(aes(x=ol.mds3[573,1],y=ol.mds3[573,2]),size=5,shape=18)
```
Судя по графику это масло похоже на выброс. Причина в большом показателе linolenic.